{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAq3-v_peF9P",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[![AnalyticsDojo](https://github.com/rpi-techfundamentals/fall2018-materials/blob/master/fig/final-logo.png?raw=1)](http://rpi.analyticsdojo.com)\n",
    "<center><h1>Revisting Boston Housing with Pytorch</h1></center>\n",
    "<center><h3><a href = 'http://rpi.analyticsdojo.com'>rpi.analyticsdojo.com</a></h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisting Boston Housing with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssNHzVxmeUho"
   },
   "outputs": [],
   "source": [
    "#!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Usm1-07eF9U"
   },
   "outputs": [],
   "source": [
    "#Let's get rid of some imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Define the model \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ey6rkOdbeF9d",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview\n",
    "- Getting the Data\n",
    "- Reviewing Data\n",
    "- Modeling \n",
    "- Model Evaluation\n",
    "- Using Model\n",
    "- Storing Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wcvspWkeF9f",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Getting Data \n",
    "- Available in the [sklearn package](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) as a Bunch object (dictionary).\n",
    "- From FAQ: [\"Donâ€™t make a bunch object! They are not part of the scikit-learn API. Bunch objects are just a way to package some numpy arrays. As a scikit-learn user you only ever need numpy arrays to feed your model with data.\"](http://scikit-learn.org/stable/faq.html)\n",
    "- Available in the UCI data repository. \n",
    "- Better to convert to Pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8nkKvL4eF9o"
   },
   "outputs": [],
   "source": [
    "#From sklearn tutorial.\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print( \"Type of boston dataset:\", type(boston))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBPIWOQDeF9s"
   },
   "outputs": [],
   "source": [
    "#A bunch is you remember is a dictionary based dataset.  Dictionaries are addressed by keys. \n",
    "#Let's look at the keys. \n",
    "print(boston.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFOdZXNKeF9x",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#DESCR sounds like it could be useful. Let's print the description.\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFUWt9YJeF92",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's change the data to a Panda's Dataframe\n",
    "import pandas as pd\n",
    "boston_df = pd.DataFrame(boston['data'] )\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmWBxnVNeF95",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Now add the column names.\n",
    "boston_df.columns = boston['feature_names']\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSqG7J-GeF99",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Add the target as PRICE. \n",
    "boston_df['PRICE']= boston['target']\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJHf2nYceF-B",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ## Attribute Information (in order):\n",
    " Looks like they are all continuous IV and continuous DV. \n",
    "        - CRIM     per capita crime rate by town\n",
    "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "        - INDUS    proportion of non-retail business acres per town\n",
    "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "        - NOX      nitric oxides concentration (parts per 10 million)\n",
    "        - RM       average number of rooms per dwelling\n",
    "        - AGE      proportion of owner-occupied units built prior to 1940\n",
    "        - DIS      weighted distances to five Boston employment centres\n",
    "        - RAD      index of accessibility to radial highways\n",
    "        - TAX      full-value property-tax rate per 10,000\n",
    "        - PTRATIO  pupil-teacher ratio by town\n",
    "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "        - LSTAT    % lower status of the population\n",
    "        - MEDV     Median value of owner-occupied homes in 1000's\n",
    " Let's check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17iYyvMNeF-D",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#check for missing values\n",
    "print(np.sum(np.isnan(boston_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31VBYJCXeF-K",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What type of data are there?\n",
    "- First let's focus on the dependent variable, as the nature of the DV is critical to selection of model. \n",
    "- *Median value of owner-occupied homes in $1000's* is the Dependent Variable  (continuous variable).\n",
    "- It is relevant to look at the distribution of the dependent variable, so let's do that first.\n",
    "- Here there is a normal distribution for the most part, with some at the top end of the distribution we could explore later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMC1ywHPeF-N"
   },
   "outputs": [],
   "source": [
    "#Let's us seaborn, because it is pretty. ;) \n",
    "#See more here. http://seaborn.pydata.org/tutorial/distributions.html\n",
    "import seaborn as sns\n",
    "sns.distplot(boston_df['PRICE']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uq7gI9seF-R",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#We can quickly look at other data. \n",
    "#Look at the bottom row to see thinks likely coorelated with price. \n",
    "#Look along the diagonal to see histograms of each. \n",
    "sns.pairplot(boston_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zfa7DQNheF-U",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Preparing to Model \n",
    "- It is common to separate `y` as the dependent variable and `X` as the matrix of independent variables.\n",
    "- Here we are using `train_test_split` to split the test and train.\n",
    "- This creates 4 subsets, with IV and DV separted: `X_train, X_test, y_train, y_test`\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89UDBeWFeF-W"
   },
   "outputs": [],
   "source": [
    "#This will throw and error at import if haven't upgraded. \n",
    "# from sklearn.cross_validation  import train_test_split  \n",
    "from sklearn.model_selection  import train_test_split\n",
    "#y is the dependent variable.\n",
    "y = boston_df['PRICE']\n",
    "#As we know, iloc is used to slice the array by index number. Here this is the matrix of \n",
    "#independent variables.\n",
    "X = boston_df.iloc[:,0:13]\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbbYVzFTfAJL"
   },
   "outputs": [],
   "source": [
    "#Define training hyperprameters.\n",
    "batch_size = 50\n",
    "num_epochs = 200\n",
    "learning_rate = 0.01\n",
    "size_hidden= 100\n",
    "\n",
    "#Calculate some other hyperparameters based on data.  \n",
    "batch_no = len(X_train) // batch_size  #batches\n",
    "cols=X_train.shape[1] #Number of columns in input matrix\n",
    "n_output=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xD9PhAU7hoqT"
   },
   "outputs": [],
   "source": [
    "#Create the model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(\"Executing the model on :\",device)\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, size_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(cols, size_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(size_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "net = Net(cols, size_hidden, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dE9a54SijQEs"
   },
   "outputs": [],
   "source": [
    "#Adam is a specific flavor of gradient decent which is typically better\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "criterion = torch.nn.MSELoss(size_average=False)  # this is for regression mean squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1-OhvPsk6aM"
   },
   "outputs": [],
   "source": [
    "#Change to numpy arraay. \n",
    "X_train=X_train.values\n",
    "y_train=y_train.values\n",
    "X_test=X_test.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nyf8hhaijqFA"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "running_loss = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    #Shuffle just mixes up the dataset between epocs\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    # Mini batch learning\n",
    "    for i in range(batch_no):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "        labels = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print(\"outputs\",outputs)\n",
    "        #print(\"outputs\",outputs,outputs.shape,\"labels\",labels, labels.shape)\n",
    "        loss = criterion(outputs, torch.unsqueeze(labels,dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print('Epoch {}'.format(epoch+1), \"loss: \",running_loss)\n",
    "    running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4QTTcBF3aeZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = Variable(torch.FloatTensor(X_train)) \n",
    "result = net(X)\n",
    "pred=result.data[:,0].numpy()\n",
    "print(len(pred),len(y_train))\n",
    "r2_score(pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAsEl1qyuSrH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "#This is a little bit tricky to get the resulting prediction.  \n",
    "def calculate_r2(x,y=[]):\n",
    "    \"\"\"\n",
    "    This function will return the r2 if passed x and y or return predictions if just passed x. \n",
    "    \"\"\"\n",
    "    # Evaluate the model with the test set. \n",
    "    X = Variable(torch.FloatTensor(x))  \n",
    "    result = net(X) #This outputs the value for regression\n",
    "    result=result.data[:,0].numpy()\n",
    "  \n",
    "    if len(y) != 0:\n",
    "        r2=r2_score(result, y)\n",
    "        print(\"R-Squared\", r2)\n",
    "        #print('Accuracy {:.2f}'.format(num_right / len(y)), \"for a total of \", len(y), \"records\")\n",
    "        return pd.DataFrame(data= {'actual': y, 'predicted': result})\n",
    "    else:\n",
    "        print(\"returning predictions\")\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJ451DaG5yXb"
   },
   "outputs": [],
   "source": [
    "result1=calculate_r2(X_train,y_train)\n",
    "result2=calculate_r2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4mhnevoeF-Y",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modeling \n",
    "- First import the package: `from sklearn.linear_model import LinearRegression`\n",
    "- Then create the model object.  \n",
    "- Then fit the data. \n",
    "- This creates a trained model (an object) of class regression.\n",
    "- The variety of methods and attributes available for regression are shown [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcWl-I5BeF-Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit( X_train, y_train )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fbnv9I0ueF-e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluating the Model Results\n",
    "- You have fit a model. \n",
    "- You can now store this model, save the object to disk, or evaluate it with different outcomes. \n",
    "- Trained regression objects have coefficients (`coef_`) and intercepts (`intercept_`) as attributes. \n",
    "- R-Squared is determined from the `score` method of the regression object.\n",
    "- For Regression, we are going to use the coefficient of determination as our way of evaluating the results, [also referred to as R-Squared](https://en.wikipedia.org/wiki/Coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lkam3qKNeF-f"
   },
   "outputs": [],
   "source": [
    "\n",
    "print('R2 for Train)', lm.score( X_train, y_train ))\n",
    "print('R2 for Test (cross validation)', lm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-oXxeTweF_G"
   },
   "source": [
    "\n",
    "Copyright [AnalyticsDojo](http://rpi.analyticsdojo.com) 2016.\n",
    "This work is licensed under the [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/) license agreement.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "regression-boston-housing-pytorch.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/rpi-techfundamentals/fall2018-materials/blob/master/07-intro-modeling2/02-regression-boston-housing-python.ipynb",
     "timestamp": 1543276896373
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}